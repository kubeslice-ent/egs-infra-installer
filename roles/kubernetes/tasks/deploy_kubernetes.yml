---
- name: Check if Kubernetes deployment is enabled
  fail:
    msg: "Kubernetes deployment is disabled in user_input.yml"
  when: not kubernetes_deployment.enabled | default(false)

- name: Display current working directory
  command: pwd
  register: current_dir
  changed_when: false
  when: kubernetes_deployment.enabled | default(false)

- name: Read user_input.yml
  slurp:
    src: "{{ playbook_dir }}/user_input.yml"
  register: user_input_content
  when: kubernetes_deployment.enabled | default(false)

- name: Parse user_input.yml content
  set_fact:
    user_input: "{{ user_input_content.content | b64decode | from_yaml }}"
  when: kubernetes_deployment.enabled | default(false)

- name: Set Kubespray variables
  set_fact:
    kube_apiserver_ip: "{{ kubernetes_deployment.api_server.host }}"
    loadbalancer_apiserver:
      address: "{{ kubernetes_deployment.api_server.host }}"
      port: "{{ kubernetes_deployment.api_server.port }}"
  when: kubernetes_deployment.enabled | default(false)

- name: Generate inventory content
  template:
    src: "{{ playbook_dir }}/templates/inventory.ini.j2"
    dest: "{{ inventory_dir }}/kubespray/inventory.ini"
  vars:
    control_plane_nodes: "{{ kubernetes_deployment.control_plane_nodes }}"
    worker_nodes: "{{ kubernetes_deployment.worker_nodes | default([]) }}"
    ssh_key_path: "{{ kubernetes_deployment.ssh_key_path | default('~/.ssh/k8s_rsa') }}"
    default_ansible_user: "{{ kubernetes_deployment.default_ansible_user | default('root') }}"
    kube_apiserver_ip: "{{ kubernetes_deployment.api_server.host }}"
  when: kubernetes_deployment.enabled | default(false)

- name: Show generated inventory file contents
  command: cat {{ inventory_dir }}/kubespray/inventory.ini
  register: inventory_contents
  changed_when: false
  when: kubernetes_deployment.enabled | default(false)

- name: Display debug information
  debug:
    msg: |
      Current Directory: {{ current_dir.stdout }}
      Inventory Path: {{ inventory_dir }}/kubespray/inventory.ini
      Kubespray Dir: {{ kubespray_dir }}
      Group Vars Path: {{ inventory_dir }}/kubespray/group_vars/all/all.yml
  when: kubernetes_deployment.enabled | default(false)

- name: Test SSH connection to all hosts
  command:
    cmd: "ssh -i {{ kubernetes_deployment.ssh_key_path | expanduser | realpath }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null {{ item.ansible_user | default('root') }}@{{ item.ansible_host }} 'echo SSH connection successful'"
  loop: "{{ kubernetes_deployment.control_plane_nodes + kubernetes_deployment.worker_nodes | default([]) }}"
  register: ssh_test
  changed_when: false
  ignore_errors: true
  when: kubernetes_deployment.enabled | default(false)

- name: Display SSH test results
  debug:
    var: ssh_test
  when: kubernetes_deployment.enabled | default(false)

- name: Set Ansible environment variables
  set_fact:
    ansible_env_vars: "{{ kubespray_env | combine(kubespray_extra_env) }}"
  when: kubernetes_deployment.enabled | default(false)

- name: Set default values for async execution
  set_fact:
    kubespray_async_timeout: "{{ kubespray_async_timeout | default(3600) }}"  # 1 hour default timeout
    kubespray_poll_interval: "{{ kubespray_poll_interval | default(30) }}"    # 30 seconds default poll interval
  when: kubernetes_deployment.enabled | default(false)

- name: Run Kubespray cluster deployment
  command:
    cmd: >
      ansible-playbook -i {{ inventory_dir }}/kubespray/inventory.ini
      {{ kubespray_dir }}/cluster.yml
      -e @{{ inventory_dir }}/kubespray/group_vars/all/all.yml
      -e @{{ inventory_dir }}/kubespray/group_vars/all/api_server.yml
      -e "kube_apiserver_ip={{ kubernetes_deployment.api_server.host }}"
      -e "loadbalancer_apiserver={address: '{{ kubernetes_deployment.api_server.host }}', port: {{ kubernetes_deployment.api_server.port }}}"
      -e "apiserver_loadbalancer_domain_name={{ kubernetes_deployment.api_server.host }}"
      -e "supplementary_addresses_in_ssl_keys=['{{ kubernetes_deployment.api_server.host }}']"
      --become
      --become-method={{ kubespray_become_method }}
      --become-user={{ kubespray_become_user }}
      -e ansible_ssh_private_key_file={{ kubernetes_deployment.ssh_key_path | expanduser | realpath }}
      -e ansible_user={{ kubernetes_deployment.default_ansible_user | default('root') }}
      -e ansible_become_pass=''
      --ssh-extra-args="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
      -vvvv
  environment: "{{ kubespray_env | combine(kubespray_extra_env) | combine({'ANSIBLE_CONFIG': playbook_dir + '/ansible.cfg'}) }}"
  register: kubespray_result
  async: "{{ kubespray_async_timeout }}"
  poll: "{{ kubespray_poll_interval }}"
  when: kubernetes_deployment.enabled | default(false)

- name: Display Kubespray deployment result
  debug:
    msg: |
      STDOUT:
      {{ kubespray_result.stdout_lines | default([]) | join('\n') }}
      
      STDERR:
      {{ kubespray_result.stderr_lines | default([]) | join('\n') }}
  when: kubespray_result is defined and kubernetes_deployment.enabled | default(false)

- name: Ensure files directory exists
  file:
    path: "{{ lookup('env', 'PWD') }}/files"
    state: directory
    mode: '0755'
  when: kubernetes_deployment.enabled | default(false)

- name: Try direct copy of kubeconfig from first control plane node
  command:
    cmd: "scp -i {{ kubernetes_deployment.ssh_key_path | expanduser | realpath }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null {{ kubernetes_deployment.default_ansible_user | default('root') }}@{{ kubernetes_deployment.control_plane_nodes[0].ansible_host }}:/etc/kubernetes/admin.conf {{ lookup('env', 'PWD') }}/files/kubeconfig"
  register: direct_copy_result
  ignore_errors: true
  when: 
    - kubernetes_deployment.enabled | default(false)
    - kubespray_result is defined
    - kubespray_result is succeeded

- name: Try alternative copy method using sudo if direct copy fails
  block:
    - name: Create temporary copy of admin.conf on remote host
      command:
        cmd: "ssh -i {{ kubernetes_deployment.ssh_key_path | expanduser | realpath }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null {{ kubernetes_deployment.default_ansible_user | default('root') }}@{{ kubernetes_deployment.control_plane_nodes[0].ansible_host }} 'sudo cp /etc/kubernetes/admin.conf /tmp/admin.conf && sudo chown {{ kubernetes_deployment.default_ansible_user | default('root') }}:{{ kubernetes_deployment.default_ansible_user | default('root') }} /tmp/admin.conf'"
      when: direct_copy_result is failed

    - name: Copy temporary admin.conf from remote host
      command:
        cmd: "scp -i {{ kubernetes_deployment.ssh_key_path | expanduser | realpath }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null {{ kubernetes_deployment.default_ansible_user | default('root') }}@{{ kubernetes_deployment.control_plane_nodes[0].ansible_host }}:/tmp/admin.conf {{ lookup('env', 'PWD') }}/files/kubeconfig"
      when: direct_copy_result is failed

    - name: Clean up temporary admin.conf on remote host
      command:
        cmd: "ssh -i {{ kubernetes_deployment.ssh_key_path | expanduser | realpath }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null {{ kubernetes_deployment.default_ansible_user | default('root') }}@{{ kubernetes_deployment.control_plane_nodes[0].ansible_host }} 'sudo rm -f /tmp/admin.conf'"
      when: direct_copy_result is failed
  ignore_errors: true
  when:
    - kubernetes_deployment.enabled | default(false)
    - kubespray_result is defined
    - kubespray_result is succeeded
    - direct_copy_result is failed

- name: Set kubeconfig permissions
  file:
    path: "{{ lookup('env', 'PWD') }}/files/kubeconfig"
    mode: '0600'
  when: 
    - kubernetes_deployment.enabled | default(false)
    - kubespray_result is defined
    - kubespray_result is succeeded 