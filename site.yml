# site.yml
# Master playbook for smartscaler-apps-installer
---
# Main playbook for cluster deployment
- name: Load global variables
  hosts: localhost
  gather_facts: false
  vars_files:
    - user_input.yml
  tasks:
    - name: Set global variables
      set_fact:
        kubernetes_deployment: "{{ kubernetes_deployment }}"
        metallb: "{{ metallb }}"
        nginx_ingress: "{{ nginx_ingress }}"
        global_control_plane_ip: "{{ global_control_plane_ip }}"
        global_kubeconfig: "{{ global_kubeconfig }}"
        global_kubecontext: "{{ global_kubecontext }}"
      delegate_to: localhost
      delegate_facts: true

- name: Deploy Smart Scaler Components
  hosts: localhost
  gather_facts: true
  vars_files:
    - "{{ lookup('env', 'VARS_FILE', default='user_input.yml') }}"

  pre_tasks:
    - name: Check if vault file exists
      stat:
        path: group_vars/all/vault.yml
      register: vault_file

    - name: Include vault file if it exists
      include_vars:
        file: group_vars/all/vault.yml
      when: vault_file.stat.exists
      ignore_errors: true


    - name: Set Avesha Docker username
      set_fact:
        avesha_docker_username: "{{ avesha_docker_username | default(lookup('env', 'AVESHA_DOCKER_USERNAME')) | default(vault_avesha_docker_username | default('not-set')) }}"

    - name: Set Avesha Docker password
      set_fact:
        avesha_docker_password: "{{ avesha_docker_password | default(lookup('env', 'AVESHA_DOCKER_PASSWORD')) | default(vault_avesha_docker_password | default('not-set')) }}"

    - name: Debug variable values
      debug:
        msg: |
          Avesha Docker Username: {{ 'set' if avesha_docker_username and avesha_docker_username != 'not-set' else 'not set' }}
          Avesha Docker Password: {{ 'set' if avesha_docker_password and avesha_docker_password != 'not-set' else 'not set' }}

    - name: Determine which credentials are needed based on execution order
      set_fact:
        needs_avesha_credentials: "{{ 'create_avesha_secret' in execution_order }}"
        missing_credentials: []

    - name: Debug credential requirements
      debug:
        msg: |
          Credential requirements based on execution order:
          - Avesha credentials needed: {{ needs_avesha_credentials }}
          - Execution order: {{ execution_order }}


    - name: Check Avesha Docker username (only if needed)
      set_fact:
        missing_credentials: "{{ missing_credentials + ['AVESHA_DOCKER_USERNAME'] }}"
      when: 
        - needs_avesha_credentials | default(false)
        - (not avesha_docker_username or avesha_docker_username == 'not-set')

    - name: Check Avesha Docker password (only if needed)
      set_fact:
        missing_credentials: "{{ missing_credentials + ['AVESHA_DOCKER_PASSWORD'] }}"
      when: 
        - needs_avesha_credentials | default(false)
        - (not avesha_docker_password or avesha_docker_password == 'not-set')

    - name: Verify required variables (only for components in execution order)
      fail:
        msg: |
          The following required variables are not set for components in your execution order:
          {% for cred in missing_credentials %}
          - {{ cred }}
          {% endfor %}
          
          Components requiring these credentials:
          {% if needs_avesha_credentials | default(false) %}
          - create_avesha_secret (Avesha credentials)
          {% endif %}
          
          Please set these variables using one of:
          1. Environment variables (export {{ missing_credentials | join('=') }})
          2. Command line arguments (-e {{ missing_credentials | map('regex_replace', '^', '') | map('lower') | map('regex_replace', '_', '_') | join('=') }})
          3. Vault file (group_vars/all/vault.yml)
          4. Direct values in user_input.yml
          5. Remove the credential-requiring components from execution_order
      when: missing_credentials | length > 0

    - name: Show credential source
      debug:
        msg: >-
          Using Avesha Systems credentials from: 
          {%- if avesha_docker_username == lookup('env', 'AVESHA_DOCKER_USERNAME') %} environment variables
          {%- elif avesha_docker_username == 'not-set' %} not configured (will use defaults)
          {%- else %} command line arguments or vault
          {%- endif %}

  tasks:
    - name: Initialize summary tracking
      include_tasks: "tasks/summary_tracker.yml"
      when: summary_enabled | default(true)

    - name: Validate prerequisites
      include_tasks: "tasks/validate_prerequisites.yml"
      when: validate_prerequisites.enabled | default(true)

    - name: Include execution order
      include_tasks: "tasks/process_execution_order.yml"
      vars:
        execution_vars:
          avesha_docker_username: "{{ avesha_docker_username }}"
          avesha_docker_password: "{{ avesha_docker_password }}"
        retry_config: "{{ retry_config | default({}) }}"
      when: execution_order_enabled | default(true)

  post_tasks:
    - name: Collect Kubernetes cluster information
      include_tasks: "tasks/collect_k8s_summary.yml"
      when: 
        - summary_enabled | default(true)
        - global_kubeconfig is defined

    - name: Generate final summary report
      include_tasks: "tasks/summary_tracker.yml"
      vars:
        generate_summary_report: true
        generate_k8s_summary_report: true
        should_save_summary: "{{ save_summary_to_file | default(true) }}"
      when: summary_enabled | default(true)

    - name: Display installation completion message
      debug:
        msg: |
          
          🎉 Smart Scaler installation process completed!
          
          {% if save_summary_to_file | default(true) %}
          📄 Summary report saved to: output/installation_summary_{{ ansible_date_time.epoch }}.md
          {% endif %}
          
          🔍 Check the summary above for detailed results.
          
          💡 Next steps:
          • Verify all components are running: kubectl get pods --all-namespaces
          • Check service endpoints: kubectl get services --all-namespaces
          • Review logs for any issues: kubectl logs <pod-name> -n <namespace>
          • All output files are saved in the ./output/ directory
      when: summary_enabled | default(true)